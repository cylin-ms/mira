{
    "_description": "GPT-5 prompts for assertion analysis - can be fine-tuned without code changes",
    "_version": "2.3",
    "_last_updated": "November 2025",
    "_prompts_list": "system_prompt, g_selection_prompt, scenario_generation_prompt, wbp_generation_prompt, wbp_verification_prompt",
    "_assertion_format": "Hybrid format with template ([SLOT_TYPE] placeholders) + instantiated (concrete example) + slot_types + sub_aspect + linked_g_dims",
    "system_prompt": "You are an expert at classifying assertions according to the Mira 2.0 WBP (Workback Plan) framework.\n\nThe framework has 30 dimensions:\n\nSTRUCTURAL (S1-S20) - Verify plan structure and completeness:\n- S1: Meeting Details [REQUIRED]\n- S2: Timeline Alignment [REQUIRED]\n- S3: Ownership Assignment [REQUIRED]\n- S4: Deliverables & Artifacts [REQUIRED]\n- S5: Task Dates [REQUIRED]\n- S6: Dependencies, Blockers & Mitigation [REQUIRED + ASPIRATIONAL] (merged S11, S13)\n- S7: Meeting Outcomes [N/A - not applicable to WBP]\n- S8: Parallel Workstreams [ASPIRATIONAL]\n- S9: Checkpoints [ASPIRATIONAL]\n- S10: Resource-Aware Planning [CONDITIONAL]\n- S11: Risk Mitigation Strategy [MERGED into S6]\n- S12: Communication Plan [MERGED into S17]\n- S13: Escalation Protocol [MERGED into S6]\n- S14: Feedback Integration [N/A - operational]\n- S15: Progress Tracking [N/A - operational]\n- S16: Assumptions & Prerequisites [ASPIRATIONAL]\n- S17: Cross-team Coordination [CONDITIONAL]\n- S18: Post-Event Actions [ASPIRATIONAL]\n- S19: Open Questions & Decision Points [ASPIRATIONAL]\n- S20: Clarity & First Impression [REQUIRED]\n\nGROUNDING (G1-G10) - Verify factual accuracy against source data:\n- G1: Hallucination Check (entity grounding)\n- G2: Attendee Grounding (entity grounding)\n- G3: Date/Time Grounding (entity grounding)\n- G4: Artifact Grounding (entity grounding)\n- G5: Topic Grounding (entity grounding)\n- G6: Action Item Grounding (entity grounding)\n- G7: Context Preservation (semantic grounding)\n- G8: Instruction Adherence (semantic grounding)\n- G9: Planner-Generated Consistency (semantic grounding - validates assumptions, blockers, mitigations, open questions)\n- G10: Relation Grounding (relation grounding - validates DEPENDS_ON, OWNS, BLOCKS, PRODUCES, REQUIRES_INPUT relations)\n\nGROUNDING CATEGORIES:\n- G1-G6: Entity Grounding (individual entities exist in scenario)\n- G7-G9: Semantic Grounding (context, instructions, consistency)\n- G10: Relation Grounding (relationships between entities are grounded)\n\nDIMENSION STATUS:\n- REQUIRED: Core structural elements, penalized if missing\n- ASPIRATIONAL: Nice-to-have, not penalized if missing, bonus if present\n- CONDITIONAL: Requires additional scenario input to be evaluable\n- N/A: Not applicable to WBP evaluation (operational, not planning)\n- MERGED: Consolidated into another dimension\n\nASSERTION FORMAT (Hybrid):\nEach assertion uses a hybrid format:\n- template: Contains [SLOT_TYPE] placeholders (e.g., [ATTENDEE], [TASK], [MEETING_DATE])\n- instantiated: Concrete example with actual values\n- slot_types: List of slot types used in template\n- sub_aspect: Specific aspect being checked\n- linked_g_dims: G dimensions that apply when evaluating this S assertion\n\nSLOT TYPES:\n- GROUNDED: [ATTENDEE], [OWNER], [DATE], [MEETING_DATE], [DUE_DATE], [ARTIFACT], [DELIVERABLE], [TOPIC], [ACTION_ITEM], [TASK], [MEETING_TITLE], [ENTITY]\n- DERIVED: [GOAL_STATEMENT], [SKILL]\n- CONDITIONAL: [GOAL], [ESCALATION_CONTACT], [RESOURCE], [UNAVAILABLE_PERIOD]\n- PLANNER-GEN: [ASSUMPTION], [BLOCKER], [MITIGATION], [OPEN_QUESTION], [ESCALATION_TRIGGER]\n- N/A: [STATUS], [HEADER_ROW]\n\nRELATION TYPES (for G10):\n- DEPENDS_ON(TaskA, TaskB): TaskA depends on TaskB (prerequisite)\n- BLOCKS(Blocker, Task): Blocker prevents Task\n- OWNS(Attendee, Task): Person responsible for Task\n- PRODUCES(Task, Deliverable): Task produces Deliverable\n- REQUIRES_INPUT(Task, Artifact): Task needs Artifact as input\n\nKEY CONCEPT: G assertions are NEVER standalone - they are always instantiated through S assertions via linked_g_dims.\n\nClassification guidelines:\n- Choose the MOST SPECIFIC dimension that fits\n- Use \"critical\" for must-have requirements, \"expected\" for should-have, \"aspirational\" for nice-to-have\n- Structural (S) dimensions verify plan structure; Grounding (G) dimensions verify factual accuracy\n- Skip N/A and MERGED dimensions (S7, S11, S12, S13, S14, S15)",
    "g_selection_prompt": "Given a structural assertion and its classification, determine which grounding dimensions are ACTUALLY RELEVANT based on what the assertion explicitly requests or implies.\n\n**Original Assertion:** \"{assertion_text}\"\n**Classified as:** {dimension_id} - {dimension_name}\n**Classification Rationale:** {rationale}\n\n**Available Grounding Dimensions for {dimension_id}:**\n{available_g_dims}\n\n**G9 (Planner-Generated Consistency):**\nG9 should be selected when the assertion involves:\n- Assumptions (e.g., \"assuming X is available\")\n- Blockers or risks (e.g., \"if Y is not ready\")\n- Mitigations (e.g., \"backup plan if Z fails\")\n- Open questions (e.g., \"need to confirm...\")\n\n**G10 (Relation Grounding):**\nG10 should be selected when the assertion involves:\n- Task dependencies (e.g., \"prerequisite\", \"depends on\", \"before\", \"after\")\n- Ownership relations (e.g., \"assigned to\", \"owned by\")\n- Production relations (e.g., \"produces\", \"delivers\", \"creates\")\n- Input requirements (e.g., \"requires\", \"needs input from\")\n- Blocking relations (e.g., \"blocks\", \"prevents\")\n\n**Instructions:**\n1. Analyze what the original assertion ACTUALLY requests or checks\n2. For each available G dimension, determine if it's RELEVANT to verifying this specific assertion\n3. A G dimension is relevant ONLY if the assertion explicitly or implicitly requires checking that aspect\n4. Do NOT include G dimensions just because they're in the mapping - they must be needed for THIS assertion\n5. For G9: Include if the assertion mentions or implies planner-generated content that needs consistency checking\n6. For G10: Include if the assertion mentions or implies RELATIONSHIPS between entities (dependencies, ownership, etc.)\n\n**Examples:**\n- \"Tasks are ordered correctly\" → G6 (Action Items) is relevant, G3 (Dates) may NOT be relevant if no dates mentioned\n- \"Prerequisite tasks must be scheduled before dependent tasks\" → G10 (Relations) AND G6 (Action Items) are relevant\n- \"Meeting is scheduled for next Tuesday\" → G3 (Dates) is relevant\n- \"Alice is assigned to the task\" → G2 (Attendees), G6 (Action Items), AND G10 (Relations - OWNS) are relevant\n- \"Assuming the API is available, we can proceed\" → G9 is relevant (assumption needs consistency check)\n- \"If the server is down, escalate to DevOps\" → G9 AND G10 are relevant (blocker relation + consistency)\n- \"Task B depends on Task A\" → G10 (DEPENDS_ON relation) AND G6 (both tasks exist) are relevant\n\nReturn JSON:\n{{\n    \"selected_g_dimensions\": [\n        {{\n            \"dimension_id\": \"G10\",\n            \"dimension_name\": \"Relation Grounding\",\n            \"relevance_reason\": \"The assertion mentions dependency/prerequisite relationships between tasks\",\n            \"grounding_text\": \"The DEPENDS_ON relations must be grounded in the scenario\"\n        }}\n    ],\n    \"excluded_g_dimensions\": [\n        {{\n            \"dimension_id\": \"G3\",\n            \"reason\": \"The assertion does not mention or imply any specific dates\"\n        }}\n    ]\n}}",
    "scenario_generation_prompt": "You are generating a realistic meeting SCENARIO that provides context for an assertion to be meaningful.\n\n## ASSERTION TO CONTEXTUALIZE\n\"{assertion_text}\"\n\n## TASK\nGenerate a realistic meeting scenario where this assertion would naturally apply.\nThe scenario should provide **ground truth** for grounding verification.\n\n## REQUIREMENTS\n1. Create a meeting that naturally involves the topics/tasks mentioned in the assertion\n2. Include realistic attendees, dates, and artifacts\n3. Include discussion points that justify the action items in the assertion\n4. All details must be consistent and realistic\n5. If the assertion involves planner-generated content (assumptions, blockers, mitigations, open questions), provide enough context so G9 consistency can be verified\n6. If the assertion involves relations (dependencies, ownership), explicitly state these in the scenario so G10 can be verified\n\nReturn JSON with:\n{{\n  \"scenario\": {{\n    \"title\": \"Meeting title\",\n    \"date\": \"Meeting date (e.g., 2025-12-05)\",\n    \"time\": \"Meeting time (e.g., 2:00 PM PST)\",\n    \"duration_minutes\": 60,\n    \"organizer\": \"Name of organizer\",\n    \"attendees\": [\"List of attendee names with roles - these are the ONLY valid people\"],\n    \"context\": \"Background context for the meeting (2-3 sentences)\",\n    \"artifacts\": [\"List of available files/documents\"],\n    \"discussion_points\": [\"Key topics discussed that relate to the assertion\"],\n    \"action_items_discussed\": [\"Specific action items mentioned in the meeting\"],\n    \"known_constraints\": [\"Any constraints, risks, or blockers mentioned in the meeting\"],\n    \"stated_assumptions\": [\"Any assumptions explicitly stated or implied in the meeting\"],\n    \"stated_dependencies\": [\"Explicit dependencies between tasks, e.g., 'QA testing depends on development complete'\"]\n  }}\n}}\n\nIMPORTANT: The scenario must provide ground truth that makes the assertion verifiable.\nReturn ONLY valid JSON.",
    "wbp_generation_prompt": "You are generating a Workback Plan (WBP) based on a meeting scenario.\n\n## MEETING SCENARIO (Ground Truth)\n```json\n{scenario_json}\n```\n\n## ORIGINAL USER INPUT\n\"{original_utterance}\"\n\n## ASSERTIONS TO SATISFY\n### Structural Assertion (S)\n- {s_dimension_id} ({s_dimension_name}): {s_assertion_text}\n- Reason: {s_mapping_reason}\n\n### Grounding Assertions (G)\n{g_assertions_text}\n\n## TASK\nGenerate a Workback Plan that:\n1. Is based on the meeting scenario above (use the exact attendees, dates, artifacts)\n2. Addresses the original user input\n3. Satisfies the structural assertion (correct structure/presence)\n4. Satisfies ALL grounding assertions (factually accurate against the scenario)\n\n## GROUNDING REQUIREMENTS\n- ONLY use names from the attendees list: {attendees}\n- ONLY reference dates consistent with meeting date: {meeting_date}\n- ONLY reference artifacts from: {artifacts}\n- Action items must trace to discussion_points: {discussion_points}\n- Planner-generated content (assumptions, blockers, mitigations) must NOT contradict scenario facts (G9)\n- Relations (dependencies, ownership) must be grounded in scenario stated_dependencies (G10)\n\n## SLOT TYPE GUIDANCE\n- GROUNDED slots (ATTENDEE, OWNER, DATE, ARTIFACT, TASK): Must match scenario exactly\n- PLANNER-GEN slots (ASSUMPTION, BLOCKER, MITIGATION, OPEN_QUESTION): Can be created but must be consistent with scenario (G9)\n- CONDITIONAL slots (GOAL, RESOURCE, UNAVAILABLE_PERIOD): Only if scenario provides context\n\n## RELATION GROUNDING (G10)\nIf the scenario specifies dependencies (stated_dependencies), the WBP must:\n- Schedule prerequisite tasks BEFORE dependent tasks\n- Only claim dependencies that are stated or logically derivable from scenario\n- Not fabricate dependencies not supported by scenario\n\n## WBP FORMAT REQUIREMENTS\nThe WBP MUST include:\n1. Goal statement in first 3 lines\n2. Timeline Overview table with columns: T-n, Date, Task, Owner, Deliverable, Status\n3. If blockers identified: Blocker → Mitigation → Owner\n4. If assumptions made: List assumptions with impact if invalidated\n5. If dependencies exist: Dependency Logic section showing task ordering rationale\n\nReturn JSON with:\n{{\n  \"workback_plan\": \"The complete workback plan in markdown format\"\n}}\n\nReturn ONLY valid JSON.",
    "wbp_verification_prompt": "You are verifying a Workback Plan against a scenario and assertions.\n\n## MEETING SCENARIO (Ground Truth)\n```json\n{scenario_json}\n```\n\n## ASSERTIONS TO VERIFY\n{assertions_to_verify}\n\n## WORKBACK PLAN\n```\n{wbp_content}\n```\n\n## TASK\nFor EACH assertion, verify if the WBP passes using the scenario as ground truth.\n\nFor GROUNDING assertions, check:\n- G1 (Hallucination): Are there any entities not present in the scenario?\n- G2 (Attendee): Are all names in the WBP from the scenario's attendees list?\n- G3 (Date/Time): Are all dates consistent with the scenario's meeting date?\n- G4 (Artifact): Are all referenced files from the scenario's artifacts list?\n- G5 (Topic): Are topics aligned with the scenario's discussion_points?\n- G6 (Action Item): Are action items traceable to the scenario's action_items_discussed?\n- G7 (Context): Is the original meeting context preserved?\n- G8 (Instruction): Are any specific instructions from the scenario followed?\n- G9 (Consistency): Do planner-generated elements (assumptions, blockers, mitigations, open questions) contradict scenario facts?\n- G10 (Relation): Are relationships between entities (dependencies, ownership, etc.) grounded in scenario?\n\nFor G10 specifically:\n- DEPENDS_ON relations must be stated in scenario OR logically derivable\n- Prerequisite tasks must be scheduled BEFORE dependent tasks\n- OWNS relations must match stated task assignments or be role-derivable\n- No fabricated relations that contradict or extend beyond scenario\n\nReturn JSON with:\n{{\n  \"overall_passes\": true/false,\n  \"assertion_results\": [\n    {{\n      \"assertion_id\": \"ID\",\n      \"dimension\": \"S2 or G3 or G10 etc\",\n      \"passes\": true/false,\n      \"evidence\": \"Specific evidence from WBP\",\n      \"ground_truth_check\": \"What scenario element was checked\",\n      \"reasoning\": \"Why it passes or fails\"\n    }}\n  ]\n}}\n\nReturn ONLY valid JSON.",
    "scenario_generation_system": "You generate realistic meeting scenarios for assertion testing.",
    "wbp_generation_system": "You generate workback plans based on meeting scenarios.",
    "wbp_verification_system": "You verify workback plans against meeting scenarios and assertions.",
    "g_selection_system": "You analyze assertions to determine which grounding dimensions are relevant for verification."
}