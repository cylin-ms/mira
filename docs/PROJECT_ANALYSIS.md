# Project Analysis: Assertion Generation & Matching System

**Author:** Chin-Yew Lin  
**Date:** November 26, 2025

---

## Executive Summary

This project implements an **AI evaluation framework** for validating workback plans generated by Large Language Models (LLMs). It provides tools for generating meeting preparation plans, creating quality assertions, and automatically matching evidence in LLM responses to verify accuracy.

---

## Project Overview

### Purpose

The system addresses the challenge of evaluating LLM-generated content quality in enterprise productivity scenarios. Specifically, it:

1. **Generates workback plans** from meeting contexts using LLMs
2. **Creates structured assertions** to define quality criteria
3. **Matches assertions** against generated responses to measure accuracy
4. **Visualizes results** for human review and analysis

### Architecture

The project uses a **two-phase architecture**:

| Phase | Component | Description |
|-------|-----------|-------------|
| **Phase 1** | Offline Pre-computation | Uses a powerful LLM (e.g., `gpt-oss:20b` via Ollama) to analyze responses and find supporting evidence |
| **Phase 2** | Visualization | Streamlit application displays pre-computed matches with no runtime inference |

---

## Key Components

### 1. Assertion Matching Engine (`compute_assertion_matches.py`)

- Connects to Ollama API for LLM inference
- Processes assertions in batches for efficiency
- Scores sentence relevance (0.0-1.0) against assertion text
- Outputs enhanced JSONL with `matched_segments` per assertion

### 2. Visualization Interface (`visualize_output.py`)

- Streamlit-based web application
- Interactive exploration of generated plans
- Color-coded assertion highlighting
- Entity cards for users, files, events, and other context

### 3. Data Files

| File | Purpose |
|------|---------|
| `LOD_1121.jsonl` | Input meeting context data (users, utterances, grounding entities) |
| `output_v2.jsonl` | Generated workback plans with assertions |
| `output_v2_with_matches.jsonl` | Plans with pre-computed evidence matches |
| `step1_v2.md` | LLM prompt for workback plan generation |

---

## Data Pipeline

```
┌─────────────────────────────────────────────────────────────────┐
│                      DATA GENERATION FLOW                        │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│   LOD_1121.jsonl ──────► step1_v2.md (Prompt) ──────►           │
│   (Meeting Context)         │                                    │
│                             ▼                                    │
│                      output_v2.jsonl                             │
│                   (Plans + Assertions)                           │
│                             │                                    │
│                             ▼                                    │
│              compute_assertion_matches.py                        │
│                    (LLM via Ollama)                              │
│                             │                                    │
│                             ▼                                    │
│              output_v2_with_matches.jsonl                        │
│                 (Plans + Evidence)                               │
│                             │                                    │
│                             ▼                                    │
│                  visualize_output.py                             │
│                 (Interactive Review)                             │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

---

## Assertion Framework

### Assertion Levels

Assertions are categorized by criticality:

| Level | Description | Example |
|-------|-------------|---------|
| **Critical** | Must be present for plan validity | Correct meeting name, assumed date, owner assignments |
| **Expected** | Should be present for completeness | Timeline structure, task dependencies, pre-read materials |
| **Aspirational** | Enhances quality beyond requirements | Follow-up suggestions, visual timeline offers |

### Assertion Structure

```json
{
  "text": "The response identifies Shakia as the meeting organizer.",
  "level": "critical",
  "reasoning": {
    "reason": "User context confirms Shakia is the requestor...",
    "source": "User context and reference plan"
  },
  "matched_segments": [
    "Shakia Gencarelli (You, Senior Software Engineer) as the facilitator",
    "Organizer: Shakia"
  ]
}
```

---

## Workback Plan Methodology

Based on Weiwei Cui's methodology (`deriving_assertions_workback_plan.md`), a quality workback plan includes:

### Key Attributes

1. **Objective and Scope** - Meeting outcomes and boundaries
2. **Timeline / Reverse Schedule** - Tasks anchored to meeting date (T-10, T-5, etc.)
3. **Tasks and Owners** - Concrete activities with responsible parties
4. **Critical Path and Dependencies** - Task sequencing and blockers
5. **Deliverables and Artifacts** - Explicit outputs per task
6. **Acceptance Criteria** - Conditions for meeting readiness

### Two-Stage Assertion Derivation

- **Stage 1**: Collect key information (urgency, goals, prerequisites, tasks, dependencies)
- **Stage 2**: Determine plan depth (Minimal/Standard/Detailed) and generate assertions

---

## Technology Stack

| Technology | Purpose |
|------------|---------|
| **Python 3.10+** | Core runtime |
| **Streamlit** | Web-based visualization |
| **Ollama** | Local LLM hosting |
| **Requests** | HTTP API communication |

---

## Usage Instructions

### View Pre-computed Results

```bash
streamlit run visualize_output.py
```

### Re-compute Assertion Matches

```bash
# Ensure Ollama is running
ollama serve

# Pull the model
ollama pull gpt-oss:20b

# Run matching
python compute_assertion_matches.py \
  --input docs/output_v2.jsonl \
  --output docs/output_v2_with_matches.jsonl \
  --model gpt-oss:20b
```

---

## Project Contributors

| Contributor | Role |
|-------------|------|
| **Kening Ren** | Main developer, visualization, prompt design |
| **Weiwei Cui** | Assertion methodology, data generation |
| **Wei-Wei Cui** | Test Tenant LOD data source |

---

## Key Findings

### Strengths

1. **Robust Evaluation Framework** - Systematic approach to LLM quality assessment
2. **Enterprise Grounding** - Uses realistic enterprise data (users, files, meetings, chats)
3. **Scalable Architecture** - Offline computation enables fast UI without runtime inference
4. **Multi-level Assertions** - Critical/Expected/Aspirational hierarchy captures quality nuances

### Observations

1. **20 sample workback plans** are included in the dataset covering various meeting types:
   - CI/CD Pipeline discussions
   - JWT Cache Integration workshops
   - DevSecOps governance sessions
   - Security pipeline reviews
   - Performance deep dives

2. **Comprehensive assertion coverage** - Each plan has 8-15 assertions covering:
   - Meeting identification accuracy
   - Temporal reasoning correctness
   - Stakeholder assignment validity
   - Document reference accuracy
   - Dependency chain logic

3. **Evidence matching** enables explainable evaluation - reviewers can see exactly which text supports each assertion

---

## Future Considerations

1. **Automated scoring** - Aggregate assertion match rates into quality scores
2. **Regression testing** - Track quality changes across model versions
3. **Extended entity types** - Support additional enterprise data sources
4. **Real-time matching** - Faster models could enable live evaluation

---

## Conclusion

This project provides a well-designed framework for evaluating LLM-generated workback plans. The combination of structured assertions, offline evidence matching, and interactive visualization creates a practical system for assessing AI assistant quality in enterprise productivity scenarios.

The methodology is extensible to other LLM evaluation tasks where response quality can be decomposed into verifiable assertions grounded in input context.
