# WBP Assertion Dataset Analysis Report

**Date:** November 29, 2025  
**Analyst:** GitHub Copilot  
**Dataset:** `assertions_converted_full.jsonl` (Mira 2.0 WBP Format)

---

## Executive Summary

The WBP assertion dataset contains **224 meeting entries** derived from **47 unique user queries**. Each unique query has multiple response variations, making this a **response quality evaluation dataset** rather than a collection of distinct meetings.

---

## Key Findings

### 1. Dataset Structure

| Metric | Value |
|--------|-------|
| Total Entries | 224 |
| Unique Utterances | 47 |
| Duplicate Groups | 44 |
| Entries in Duplicates | 221 (98.7%) |
| Unique Entries | 3 (1.3%) |
| Avg Responses per Query | ~4.8 |

### 2. Duplicate Analysis

For all 44 duplicate groups:

| Field | Status | Notes |
|-------|--------|-------|
| **Utterance** | ✅ Identical | Same user query text |
| **User ID** | ✅ Identical | Same user for each group |
| **Response** | ❌ Different | Unique model output per entry |
| **Assertions** | ❌ Different | Generated based on each response |

### 3. Response Variation Distribution

The dataset shows significant variation in response count per query:

- **Maximum:** 21 variations (lod_kere user)
- **Minimum:** 2 variations
- **Median:** ~5 variations

Top duplicate groups by size:
- `lod_kere`: 21 response variations
- `lod_mark`: 14 response variations  
- `lod_dani`: 13 response variations
- `lod_nila`: 11 response variations

### 4. User Coverage

- **17 unique users** in the dataset
- Each user has between 1-21 response variations
- User IDs follow pattern: `lod_*` (LOD test tenant)

---

## Implications for Annotation

### UI Navigation
The Mira 2.0 viewer now displays duplicate markers `[1/N]` in the sidebar to help annotators:
- Identify which response variation they're viewing
- Navigate between variations of the same query
- Track progress across all variations

### Annotation Strategy Options

1. **Full Coverage:** Annotate all 224 entries (evaluates assertion consistency across responses)
2. **Sample Per Query:** Annotate 1 representative from each of 47 unique queries
3. **Comparative:** Annotate all variations within selected query groups to compare response quality

---

## Data Provenance

```
Source: Kening's Assertions_genv2_for_LOD1126part1.jsonl (224 entries)
   ↓
Conversion: convert_kening_assertions.py (GPT-5 enhanced)
   ↓
User Enrichment: Weiwei's UseUserEntity_Part1.WithUserUrl.jsonl
   ↓
Output: assertions_converted_full.jsonl (WBP format with user info)
```

---

## Conclusion

This dataset is designed for **evaluating assertion quality across multiple response variations** for the same user query. The `[x/N]` duplicate markers in Mira 2.0 now make it clear which variation is being viewed, enabling systematic comparison of:

- Response quality consistency
- Assertion coverage across response styles
- Model output diversity analysis

---

*Report generated by GitHub Copilot for the MIRA assertion evaluation project.*
