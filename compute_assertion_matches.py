"""
Offline script to compute assertion matches using a larger LLM via Ollama.
This processes the output file and adds "matched_segments" to each assertion.
"""

import json
import os
import re
from typing import List, Dict, Optional
import argparse
import requests

def load_qwen_model():
    """
    Initialize connection to Ollama API.
    Returns a tuple of (None, model_name) for API-based usage.
    """
    print("Connecting to Ollama API...")
    model_name = "qwen3:30b"  # Default model, can be changed via --model argument
    
    # Test connection
    try:
        response = requests.post(
            'http://localhost:11434/api/generate',
            json={
                'model': model_name,
                'prompt': 'test',
                'stream': False
            },
            timeout=5
        )
        if response.status_code == 200:
            print(f"âœ“ Successfully connected to Ollama with model: {model_name}")
        else:
            print(f"Warning: Ollama returned status {response.status_code}")
    except requests.exceptions.RequestException as e:
        print(f"Error: Could not connect to Ollama at http://localhost:11434")
        print(f"Make sure Ollama is running: 'ollama serve'")
        print(f"And the model is pulled: 'ollama pull {model_name}'")
        raise
    
    return None, model_name

def split_into_sentences(text: str) -> List[str]:
    """Split text into sentences for matching."""
    # Split by periods, exclamation marks, question marks, or newlines
    sentences = re.split(r'(?<=[.!?])\s+|\n+', text)
    return [s.strip() for s in sentences if s.strip() and len(s.strip()) > 10]

def score_sentences_batch(assertion_text: str, sentences: List[str], start_idx: int, model, model_name: str) -> Dict[int, float]:
    """
    Score a batch of sentences for relevance to the assertion using Ollama API.
    
    Returns:
        Dict mapping sentence index to score (0.0-1.0)
    """
    
    prompt = f"""Given an assertion, score how well each numbered passage supports it.

Assertion: "{assertion_text}"

Passages:
{chr(10).join(f"{start_idx + i + 1}. {sent}" for i, sent in enumerate(sentences))}

Return ONLY a JSON object with scores (0.0-1.0) for relevant passages (>= 0.3):
{{"scores": {{"1": 0.9, "5": 0.7}}}}"""

    try:
        response = requests.post(
            'http://localhost:11434/api/generate',
            json={
                'model': model_name,
                'prompt': prompt,
                'stream': False,
                'options': {
                    'temperature': 0.1,
                    'top_p': 0.95
                }
            },
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            response_text = result.get('response', '')
            
            # Parse JSON response
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                scores_data = json.loads(json_match.group(0))
                scores = scores_data.get("scores", {})
                
                # Convert string keys to int and return
                return {int(k) - 1: float(v) for k, v in scores.items()}
        else:
            print(f"    Warning: API returned status {response.status_code}")
            
    except Exception as e:
        print(f"    Warning: Batch scoring failed: {e}")
    
    return {}

def find_assertion_matches(assertion_text: str, response_text: str, model, model_name: str, top_k: int = 3) -> List[str]:
    """
    Use Qwen LLM via Ollama to find where in the response the assertion is supported.
    Processes the entire response in batches to handle token limits.
    
    Args:
        assertion_text: Full assertion text
        response_text: Generated response text
        model: Unused (kept for API compatibility)
        model_name: Name of the Ollama model to use
        top_k: Number of top matches to return
    
    Returns:
        List of matched text segments from the response
    """
    
    # Split response into sentences
    sentences = split_into_sentences(response_text)
    
    if not sentences:
        return []
    
    print(f"    Processing {len(sentences)} sentences in batches...")
    
    # Process in batches to handle long responses
    batch_size = 25  # Process 25 sentences at a time
    all_scores = {}
    
    for i in range(0, len(sentences), batch_size):
        batch = sentences[i:i + batch_size]
        print(f"      Batch {i//batch_size + 1}/{(len(sentences)-1)//batch_size + 1}", end="\r")
        
        batch_scores = score_sentences_batch(assertion_text, batch, i, model, model_name)
        
        # Merge scores with global indices
        for local_idx, score in batch_scores.items():
            global_idx = i + local_idx
            if 0 <= global_idx < len(sentences):
                all_scores[global_idx] = score
    
    print()  # New line after batch processing
    
    if not all_scores:
        return []
    
    # Sort by score and take top k
    scored_sentences = [(score, idx, sentences[idx]) for idx, score in all_scores.items()]
    scored_sentences.sort(key=lambda x: x[0], reverse=True)
    
    return [sent for _, _, sent in scored_sentences[:top_k]]

def process_output_file(input_path: str, output_path: str, model, model_name: str):
    """
    Process the output JSONL file and add matched_segments to each assertion.
    """
    
    if not os.path.exists(input_path):
        print(f"Error: Input file not found: {input_path}")
        return
    
    processed_items = []
    
    with open(input_path, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            line = line.strip()
            if not line:
                continue
            
            try:
                item = json.loads(line)
            except json.JSONDecodeError:
                print(f"Warning: Could not parse line {line_num}")
                continue
            
            print(f"\nProcessing item {line_num}: {item.get('utterance', 'N/A')[:50]}...")
            
            response_text = item.get('response', '')
            assertions = item.get('assertions', [])
            
            # Process each assertion
            for i, assertion in enumerate(assertions, 1):
                assertion_text = assertion.get('text', '')
                print(f"  Assertion {i}/{len(assertions)}: {assertion_text[:60]}...")
                
                # Find matches using Ollama
                matches = find_assertion_matches(assertion_text, response_text, model, model_name)
                
                # Store matches
                assertion['matched_segments'] = matches
                print(f"    Found {len(matches)} matches")
            
            processed_items.append(item)
    
    # Write output
    with open(output_path, 'w', encoding='utf-8') as f:
        for item in processed_items:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    print(f"\nâœ… Processing complete! Output written to: {output_path}")

def main():
    parser = argparse.ArgumentParser(description='Compute assertion matches using Ollama LLM')
    parser.add_argument(
        '--input',
        default='docs/output_v2.jsonl',
        help='Input JSONL file path'
    )
    parser.add_argument(
        '--output',
        default='docs/output_v2_with_matches.jsonl',
        help='Output JSONL file path'
    )
    parser.add_argument(
        '--model',
        default='qwen3:30b',
        help='Ollama model name (default: qwen3:30b)'
    )
    
    args = parser.parse_args()
    
    print("ðŸš€ Starting assertion match computation with Ollama...")
    
    # Initialize Ollama connection
    try:
        model, model_name = load_qwen_model()
        # Override with command line argument if provided
        if args.model != 'qwen3:30b':
            model_name = args.model
            print(f"Using model: {model_name}")
    except Exception as e:
        print(f"âŒ Failed to connect to Ollama: {e}")
        return
    
    # Process file
    process_output_file(args.input, args.output, model, model_name)

if __name__ == "__main__":
    main()
